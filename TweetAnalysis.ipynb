{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "243a3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import AutoModelForSequenceClassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a86aa0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('events_set1/canada_wildfires_2016/canada_wildfires_2016_train.tsv',sep='\\t')\n",
    "test_df = pd.read_csv('events_set1/canada_wildfires_2016/canada_wildfires_2016_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4d4f0845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>735891446960623616</td>\n",
       "      <td>RT @DonBradshawNTV: How @MarshallAmpsUK came t...</td>\n",
       "      <td>other_relevant_information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731202020296818688</td>\n",
       "      <td>Red Cross distributes $30M to Fort McMurray wi...</td>\n",
       "      <td>displaced_people_and_evacuations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>733665357236342784</td>\n",
       "      <td>Interesting insights on the shifting communica...</td>\n",
       "      <td>other_relevant_information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731963038429929472</td>\n",
       "      <td>RT @globeandmail: Oil sands producers helping ...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728674838034944001</td>\n",
       "      <td>Ottawa to match Red Cross donations for Fort M...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  735891446960623616  RT @DonBradshawNTV: How @MarshallAmpsUK came t...   \n",
       "1  731202020296818688  Red Cross distributes $30M to Fort McMurray wi...   \n",
       "2  733665357236342784  Interesting insights on the shifting communica...   \n",
       "3  731963038429929472  RT @globeandmail: Oil sands producers helping ...   \n",
       "4  728674838034944001  Ottawa to match Red Cross donations for Fort M...   \n",
       "\n",
       "                              class_label  \n",
       "0              other_relevant_information  \n",
       "1        displaced_people_and_evacuations  \n",
       "2              other_relevant_information  \n",
       "3  rescue_volunteering_or_donation_effort  \n",
       "4  rescue_volunteering_or_donation_effort  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b5f0e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = [\"caution_and_advice\",\n",
    "             \"displaced_people_and_evacuations\",\n",
    "             \"infrastructure_and_utility_damage\",\n",
    "             \"injured_or_dead_people\"]\n",
    "for i in range(len(train_df)):\n",
    "    if(train_df.loc[i,'class_label'] in disasters):\n",
    "        train_df.loc[i,'labels'] = 1\n",
    "    else:\n",
    "        train_df.loc[i,'labels'] = 0\n",
    "        \n",
    "for i in range(len(test_df)):\n",
    "    if(test_df.loc[i,'class_label'] in disasters):\n",
    "        test_df.loc[i,'labels'] = 1\n",
    "    else:\n",
    "        test_df.loc[i,'labels'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d001e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['labels'] = train_df['labels'].astype(int)\n",
    "test_df['labels'] = test_df['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "eeb92824",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'tweet_text': 'text'}, inplace=True)\n",
    "test_df.rename(columns={'tweet_text': 'text'}, inplace=True)\n",
    "train_df.rename(columns={'tweet_id': 'input_ids'}, inplace=True)\n",
    "test_df.rename(columns={'tweet_id': 'input_ids'}, inplace=True)\n",
    "\n",
    "train_df.drop('class_label', axis=1, inplace=True)\n",
    "test_df.drop('class_label', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "62723dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728674116773904384</td>\n",
       "      <td>RT @FoothillsFCU23: In response the to the #Fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>729787427829612544</td>\n",
       "      <td>Redcross is offering charitable donation recei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730510385544085505</td>\n",
       "      <td>RT @globeandmail: Red Cross to transfer $50-mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>733705874594746368</td>\n",
       "      <td>Live: Emergency operations briefing on north A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>730606066023665665</td>\n",
       "      <td>$9bn fire damage to Fort McMurray, â€˜the beastâ€™...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            input_ids                                               text  \\\n",
       "0  728674116773904384  RT @FoothillsFCU23: In response the to the #Fo...   \n",
       "1  729787427829612544  Redcross is offering charitable donation recei...   \n",
       "2  730510385544085505  RT @globeandmail: Red Cross to transfer $50-mi...   \n",
       "3  733705874594746368  Live: Emergency operations briefing on north A...   \n",
       "4  730606066023665665  $9bn fire damage to Fort McMurray, â€˜the beastâ€™...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "221f1e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>735891446960623616</td>\n",
       "      <td>RT @DonBradshawNTV: How @MarshallAmpsUK came t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731202020296818688</td>\n",
       "      <td>Red Cross distributes $30M to Fort McMurray wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>733665357236342784</td>\n",
       "      <td>Interesting insights on the shifting communica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731963038429929472</td>\n",
       "      <td>RT @globeandmail: Oil sands producers helping ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728674838034944001</td>\n",
       "      <td>Ottawa to match Red Cross donations for Fort M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            input_ids                                               text  \\\n",
       "0  735891446960623616  RT @DonBradshawNTV: How @MarshallAmpsUK came t...   \n",
       "1  731202020296818688  Red Cross distributes $30M to Fort McMurray wi...   \n",
       "2  733665357236342784  Interesting insights on the shifting communica...   \n",
       "3  731963038429929472  RT @globeandmail: Oil sands producers helping ...   \n",
       "4  728674838034944001  Ottawa to match Red Cross donations for Fort M...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "94a4fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9b1d333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "22d89b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df, split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_df, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "94cd6b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7fe0aa3c7d4aa1b45fb650bf1594dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cc6e5f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5667f34955d941a1946632c32b57c9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1569 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285b8b13ba4a479e89d867291028d28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/445 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ceaf7bff13405a803fdb3d5625bba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/445 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function tokenizes the input text using the RoBERTa tokenizer. \n",
    "# It applies padding and truncation to ensure that all sequences have the same length (256 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eb7b8656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'text', 'labels', 'attention_mask'],\n",
      "    num_rows: 445\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d99035ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset format\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6fed98",
   "metadata": {},
   "source": [
    "class_names = [\"caution_and_advice\",\n",
    "             \"displaced_people_and_evacuations\",\n",
    "             \"Dont know cant judge\",\n",
    "             \"infrastructure_and_utility_damage\",\n",
    "             \"injured_or_dead_people\",\n",
    "             \"missing_or_found_people\",\n",
    "             \"not_humanitarian\",\n",
    "             \"other_relevant_information\",\n",
    "             \"requests_or_urgent_needs\",\n",
    "             \"rescue_volunteering_or_donation_effort\",\n",
    "             \"sympathy_and_support\",\n",
    "            ]\n",
    "id2label = {i: label for i, label in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d96a8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "730af6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "caution_and_advice\n",
      "1\n",
      "displaced_people_and_evacuations\n",
      "2\n",
      "Dont know cant judge\n",
      "3\n",
      "infrastructure_and_utility_damage\n",
      "4\n",
      "injured_or_dead_people\n",
      "5\n",
      "missing_or_found_people\n",
      "6\n",
      "not_humanitarian\n",
      "7\n",
      "other_relevant_information\n",
      "8\n",
      "requests_or_urgent_needs\n",
      "9\n",
      "rescue_volunteering_or_donation_effort\n",
      "10\n",
      "sympathy_and_support\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(class_names):\n",
    "    print(i)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53f7d2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "511a3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_id, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5913dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "dbd613be",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_id = \"tweets_analysis_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "42743db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1d404af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "54e74070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b2cff6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1075' max='9850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1075/9850 06:43 < 55:03, 2.66 it/s, Epoch 5.45/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.775190</td>\n",
       "      <td>0.912360</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.249159</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.774725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.495425</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.798535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.634636</td>\n",
       "      <td>0.671910</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.608300</td>\n",
       "      <td>0.642982</td>\n",
       "      <td>0.671910</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rq/fttfpph53671nf5_9s4qnwlm0000gn/T/ipykernel_93782/3586216241.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  load_accuracy = load_metric(\"accuracy\")\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1850188ac0d4273a285c5e5483e7576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9fdfdf5d314948ac7b64dcd3a998f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory tweets_analysis_test/checkpoint-197 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory tweets_analysis_test/checkpoint-394 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory tweets_analysis_test/checkpoint-591 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory tweets_analysis_test/checkpoint-788 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/harithatamvada/anaconda3/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory tweets_analysis_test/checkpoint-985 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8240040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57a16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
